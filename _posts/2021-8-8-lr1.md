---
layout: post
title: Mitigating Gender Bias in Natural Language Processing
subtitle: Literature Review
date: 2021-8-8
author: JIM
header-img: img/post-bg-coffee.jpeg
catalog: true
mathjax: true
tags:
  - Algorithm
  - Gender Bias
  - Literature Review
  - Word Embeddings
  - NLP
  - Adversarial Learning
---


[PDF](https://arxiv.org/abs/1906.08976)

Published in 2019

Cited by 140

## Mitigating Gender Bias in Natural Language Processing: Literature Review

### Intro

This paper is a literature review which enumerates
- gender bias in NLP & CV downstream tasks
- **testing metrics of gender bias**
- observations regarding gender bias
- **gender bias evaluation testsets**
- debiasing methods
    - debiasing corpora
    - **debiasing word embeddings**
    - debiasing by adjusting downstream algorithms

### Gender bias in NLP & CV downstream tasks
1. **machine translation**
2. caption generation
3. speech recognition
4. **sentiment analysis**
5. language model
6. **word embedding**

### Testing metrics of gender bias
1. Word Embedding Association Test (WEAT)
2. Sentence Encoder Association Test (SEAT)
3. Cluster bias
    - Cluster of a word $w$ can be measured as the percentage of male or female stereotypical words among the $k$ nearest neighbors of $w$'s embedding where the male or female stereotypical words are obtained through human annotation.
4. FPED & FNED via _gender-swapping_
    - These are defined as the differences in the false positive (FP) and false negative (FN), respectively, of predictions of a model between original and gender-swapped inputs. (e.g. abusive language detection)
    - The motivation is that the performance of a model should not be related to the gender component of the inputs if the inference is not related to gender.

### Gender Bias Evaluation Testsets
These datasets should have following features:
- Balanced with respect to gender (such as similar number of male references and female references).
- Single-variable (only difference is regarding gender)



| Dataset            | Task                   | Probes     |
| ------------------ | ---------------------- | ---------- |
| Winogender Schemas | Coreference Resolution | Occupation |
| WinoBias           | Coreference Resolution | Occupation |
| GAP                | Coreference Resolution | Names      |
| EEC                | Sentiment Analysis     | Emotion    |

### Debiasing methods

#### Debiasing Training Corpora
- Data Augmentation
    - gender-swapping
    - name anonymization
    - flexible, useful, easy to implement; but double the dataset, create nonsensical sentences.
- Gender Tagging
    - add meta-information
    - useful in translation, expensive to tag
- Bias Fine-Tuning
    - transfer learning from unbiased small dataset to large biased dataset
    - not good in performance

#### Debiasing Word Embeddings
**Fundamental** question: It is debatable if debiasing word embeddings is a philosophically right step towards mitigating bias in NLP.
- Removing Gender Subspace
    - flawed because the semantic definition of a given word may be closely tied to its gender component.
- **Learning Gender-Neutral Word Embeddings (Zhao et al. 2018)**
    - train the word embeddings by isolating gender information in specific dimenstions
    *- NOTE: This single paper needs careful literature review*
